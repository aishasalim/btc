import streamlit as st
import cv2
import gdown
import tensorflow as tf
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
import os
from PIL import Image
import openai
from dotenv import load_dotenv
import os
from groq import Groq
from io import BytesIO
from fpdf import FPDF
from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess_input


# Define your files and their corresponding Google Drive File IDs
FILES = {
    "cnn_model.h5": "1KnqJibUxjXr9uC1Bb7CqcAwhlb4mrZXQ",
    "resnet_model.h5": "1a0ACvvkxxX1pE_JqKP_mn1J1m1xqoEL0",
    "xception_model.weights.h5": "1lkIm-3jqk0jYi3nj9Mtxw4QQdWF97575",
}

load_dotenv()

api_key = os.getenv('GROQ_API_KEY')
openai_api_key = os.getenv('OPEN_AI_KEY')

# Set the OpenAI API key
openai.api_key = openai_api_key

# Initialize the Groq client
clientgroq = Groq(api_key=api_key)

genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))


# Create output directory for saliency maps
output_dir = 'saliency_maps'
os.makedirs(output_dir, exist_ok=True)


def download_from_drive(file_id, destination):
    """
    Downloads a file from Google Drive using its file ID.

    Args:
        file_id (str): The unique ID of the file on Google Drive.
        destination (str): The local path where the file will be saved.
    """
    if not os.path.exists(destination):
        url = f"https://drive.google.com/uc?id={file_id}"
        gdown.download(url, destination, quiet=False)
    else:
        print(f"File {destination} already exists. Skipping download.")

def generate_explanation(img_path, model_prediction, confidence, selected_llm):
    prompt = f"""
    You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.
    The saliency map was generated by a deep learning model that was trained to classify brain tumors
    as either glioma, meningioma, pituitary, or no tumor.

    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

    In your response:
    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted in light cyan, those are the regions where the model is focusing on.
    - Explain possible reasons why the model made the prediction it did.
    - Do not mention the model, do not give clues that this text was AI generated
    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan.'

    Keep your explanation to 4 sentences max. Use simple language for the explanation.

    IMPORTANT NOTE!!! Let's think step by step about this. Verify step by step.
    """

    img = Image.open(img_path)

    if selected_llm == "gemini-1.5-flash":
        # Use the genai client for gemini model
        model = genai.GenerativeModel(model_name=selected_llm)
        response = model.generate_content([prompt, img]).text
    elif selected_llm == "llama-3.2-1b-preview":
        # Use the Groq OpenAI client for llama model
        try:
            raw_response = clientgroq.chat.completions.create(
                model="llama-3.1-8b-instant", 
                messages=[{
                    "role": "user",
                    "content": prompt
                }]
            )
            response = raw_response.choices[0].message.content
        except Exception as e:
            st.error(f"Error generating explanation with Llama model: {e}")
            response = "An error occurred while generating the explanation."
    elif selected_llm == "chatgpt-4o-latest":

        completion = openai.ChatCompletion.create(
                model="gpt-4o-mini",  
                messages=[
                    {"role": "system", "content": "You are an expert neurologist."},
                    {"role": "user", "content": prompt}
                ]
            )
        response = completion.choices[0].message['content']
      
    else:
        raise ValueError(f"Unsupported LLM: {selected_llm}")

    return response

@st.cache_resource
def load_resnet_model(filename):
    # Define the path where the model will be stored
    current_dir = os.path.dirname(os.path.abspath(__file__))
    models_dir = os.path.join(current_dir, 'models')
    os.makedirs(models_dir, exist_ok=True)
    model_path = os.path.join(models_dir, filename)

    # Download the model file if it doesn't exist
    file_id = FILES.get(filename)
    if file_id:
        download_from_drive(file_id, model_path)
    else:
        st.error(f"File ID for {filename} not found in FILES dictionary.")

    # Load the model
    model = load_model(model_path)
    model.name = "ResNet"
    return model

@st.cache_resource
def load_xception_model(filename):
    # Define the path where the model weights will be stored
    current_dir = os.path.dirname(os.path.abspath(__file__))
    models_dir = os.path.join(current_dir, 'models')
    os.makedirs(models_dir, exist_ok=True)
    weights_path = os.path.join(models_dir, filename)

    # Download the weights file if it doesn't exist
    file_id = FILES.get(filename)
    if file_id:
        download_from_drive(file_id, weights_path)
    else:
        st.error(f"File ID for {filename} not found in FILES dictionary.")

    # Define the model architecture
    img_shape = (299, 299, 3)
    base_model = tf.keras.applications.Xception(include_top=False, weights=None, 
                                                input_shape=img_shape, pooling='max')

    model = Sequential([
        base_model,
        Flatten(),
        Dropout(rate=0.3),
        Dense(128, activation='relu'),
        Dropout(rate=0.25),
        Dense(4, activation='softmax')
    ])

    model.build((None,) + img_shape)

    # Compile the model
    model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy',
                  metrics=['accuracy', Precision(), Recall()])

    # Load the weights
    model.load_weights(weights_path)
    model.name = "Xception"
    return model


@st.cache_resource
def load_custom_cnn_model(filename):
    # Define the path where the model will be stored
    current_dir = os.path.dirname(os.path.abspath(__file__))
    models_dir = os.path.join(current_dir, 'models')
    os.makedirs(models_dir, exist_ok=True)
    model_path = os.path.join(models_dir, filename)

    # Download the model file if it doesn't exist
    file_id = FILES.get(filename)
    if file_id:
        download_from_drive(file_id, model_path)
    else:
        st.error(f"File ID for {filename} not found in FILES dictionary.")

    # Load the model
    model = load_model(model_path)
    model.name = "Custom_CNN"
    return model


def generate_saliency_map(model, img_array, class_index, img_size, uploaded_file):
    try:
        with tf.GradientTape() as tape:
            img_tensor = tf.convert_to_tensor(img_array)
            tape.watch(img_tensor)
            predictions = model(img_tensor)
            target_class = predictions[:, class_index]
            
            gradients = tape.gradient(target_class, img_tensor)
            gradients = tf.math.abs(gradients)
            gradients = tf.reduce_max(gradients, axis=-1)
            gradients = gradients.numpy().squeeze()

        # Resize gradients to match original image size
        gradients = cv2.resize(gradients, img_size)

        # Create a circular mask for the brain area
        center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
        radius = min(center[0], center[1]) - 10
        y, x = np.ogrid[0:gradients.shape[0], 0:gradients.shape[1]]
        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2

        # Apply mask to gradients
        gradients = gradients * mask

        # Normalize only the brain area
        brain_gradients = gradients[mask]
        if brain_gradients.max() > brain_gradients.min():
            brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
        gradients[mask] = brain_gradients

        # Apply a higher threshold
        threshold = np.percentile(gradients[mask], 80)
        gradients[gradients < threshold] = 0

        # Apply more aggressive smoothing
        gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

        # Create a heatmap overlay with enhanced contrast
        heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

        # Resize heatmap to match original image size
        heatmap = cv2.resize(heatmap, img_size)

        # Superimpose the heatmap on original image with increased opacity
        original_img = image.img_to_array(image.load_img(uploaded_file, target_size=img_size))
        superimposed_img = heatmap * 0.7 + original_img * 0.3
        superimposed_img = superimposed_img.astype(np.uint8)

        # Save the saliency map with model name to differentiate
        saliency_map_filename = f"{os.path.splitext(uploaded_file.name)[0]}_{model.name}_saliency.png"
        saliency_map_path = os.path.join(output_dir, saliency_map_filename)
        cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))
        
        return superimposed_img, saliency_map_path
    except Exception as e:
        st.error(f"Error generating saliency map: {e}")
        return None, None

# Assign unique names to models for identification
class ModelWrapper:
    def __init__(self, name, model, img_size):
        self.name = name
        self.model = model
        self.img_size = img_size

st.title('Brain Tumor Classification')
st.write("Upload an image of a brain MRI scan to classify and compare saliency maps from multiple models.")

uploaded_file = st.file_uploader("Choose an image...", type=['jpg', 'jpeg', 'png'])

if uploaded_file is not None:
    # Define available models
    available_models = [
        "Transfer Learning - Xception",
        "Custom CNN",
        "ResNet"
    ]

    # Allow multiple model selection
    selected_models = st.multiselect(
        "Select Models to Compare Saliency Maps",
        available_models,
        default=available_models  # Pre-select all models
    )

    if not selected_models:
        st.warning("Please select at least one model to proceed.")
    else:
        labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']
        
        # Load models based on selection
        models = []
        for model_name in selected_models:
            if model_name == "Transfer Learning - Xception":
                try:
                    xception_model = load_xception_model('xception_model.weights.h5')  # Ensure correct path
                    models.append(ModelWrapper(name=model_name, model=xception_model, img_size=(299, 299)))
                except Exception as e:
                    st.error(f"Error loading Xception model: {e}")
            elif model_name == "Custom CNN":
                try:
                    cnn_model = load_custom_cnn_model('cnn_model.h5')  # Ensure correct path
                    models.append(ModelWrapper(name=model_name, model=cnn_model, img_size=(224, 224)))
                except Exception as e:
                    st.error(f"Error loading Custom CNN model: {e}")
            elif model_name == "ResNet":
                try:
                    resnet_model = load_resnet_model('resnet_model.h5')  # Ensure correct path
                    models.append(ModelWrapper(name=model_name, model=resnet_model, img_size=(224, 224)))  # Adjust img_size if needed
                except Exception as e:
                    st.error(f"Error loading ResNet model: {e}")
            else:
                st.error(f"Model {model_name} not recognized.")


        # Initialize a list to keep track of predictions for explanation
        prediction_details = []
        
        # Initialize containers for results in tabs
        tabs = st.tabs([model_wrapper.name for model_wrapper in models])

        for idx, model_wrapper in enumerate(models):
            with tabs[idx]:
                st.header(f"Model: {model_wrapper.name}")

                # Preprocess the image for the current model
                try:
                    # Inside your main code where you preprocess the image
                    if model_wrapper.name == "ResNet":
                        img = image.load_img(uploaded_file, target_size=model_wrapper.img_size)
                        img_array = image.img_to_array(img)
                        img_array = np.expand_dims(img_array, axis=0)
                        img_array = resnet_preprocess_input(img_array)  # Use ResNet preprocessing
                    else:
                        img = image.load_img(uploaded_file, target_size=model_wrapper.img_size)
                        img_array = image.img_to_array(img)
                        img_array = np.expand_dims(img_array, axis=0)
                        img_array /= 255.0  # Existing preprocessing

                except Exception as e:
                    st.error(f"Error preprocessing image for {model_wrapper.name}: {e}")
                    continue

                # Make prediction
                try:
                    prediction = model_wrapper.model.predict(img_array)
                except Exception as e:
                    st.error(f"Error making prediction with {model_wrapper.name}: {e}")
                    continue

                # Get the class with the highest probability
                try:
                    class_index = np.argmax(prediction[0])
                    result = labels[class_index]
                    confidence = prediction[0][class_index]
                    probabilities = prediction[0]
                    prediction_details.append({
                        'model': model_wrapper.name,
                        'result': result,
                        'confidence': confidence,
                        'probabilities': probabilities,
                        'saliency_map_path': None  # To be updated after saliency map generation
                    })
                except Exception as e:
                    st.error(f"Error processing prediction results for {model_wrapper.name}: {e}")
                    continue

                # Display prediction and confidence
                st.markdown(f"""
                    <div style="background-color: #f0f2f6; color: #000000; padding: 15px; border-radius: 10px; margin-bottom: 15px;">
                        <div style="display: flex; justify-content: space-between; align-items: center;">
                            <div style="flex: 1; text-align: center;">
                                <h4 style="margin-bottom: 5px;">Prediction</h4>
                                <p style="font-size: 24px; font-weight: 700; color: #FF6347; margin: 0;">
                                    {result}
                                </p>
                            </div>
                            <div style="width: 2px; height: 50px; background-color: #cccccc; margin: 0 15px;"></div>
                            <div style="flex: 1; text-align: center;">
                                <h4 style="margin-bottom: 5px;">Confidence</h4>
                                <p style="font-size: 24px; font-weight: 700; color: #1E90FF; margin: 0;">
                                    {confidence * 100:.2f}%
                                </p>
                            </div>
                        </div>
                    </div>
                """, unsafe_allow_html=True)

                # Generate saliency map
                saliency_map, saliency_map_path = generate_saliency_map(
                    model_wrapper.model, img_array, class_index, model_wrapper.img_size, uploaded_file
                )

                if saliency_map is not None:
                    # Update the saliency map path in prediction_details
                    prediction_details[-1]['saliency_map_path'] = saliency_map_path

                    # Create two columns for image and saliency map
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(uploaded_file, caption='Original Image', use_container_width=True)
                    with col2:
                        st.image(saliency_map, caption='Saliency Map', use_container_width=True)

                st.markdown("---")  # Separator inside each tab

        # ====== Generate explanation based on the best model ======
        if prediction_details:
            best_prediction = prediction_details[-1]

            # Create a unique key for the LLM selection
            llm_options = ["gemini-1.5-flash", "llama-3.2-1b-preview", "chatgpt-4o-latest"]
            unique_key = f"llm_select_{idx}"

            # Add UI to select which multimodal LLM to use
            selected_llm = st.selectbox("Select LLM for Explanation Generation", llm_options, key=unique_key)

            if best_prediction['saliency_map_path']:
                explanation = generate_explanation(
                        best_prediction['saliency_map_path'],
                        best_prediction['result'],
                        best_prediction['confidence'],
                        selected_llm
                )

                st.write("## Comprehensive Explanation")
                st.write(explanation)
            else:
                st.warning("Saliency map for the best model is not available. Cannot generate explanation.")

        #  ====== Probability Distribution Across Models Chart ======
        st.write("## Probability Distribution Across Models")

        fig = go.Figure()

        for detail in prediction_details:
            fig.add_trace(go.Bar(
                x=labels,
                y=detail['probabilities'],
                name=detail['model']
            ))

        # Customize the chart layout
        fig.update_layout(
            barmode='group',
            title="Probability Distribution Across Models",
            xaxis_title="Class",
            yaxis_title="Probability",
            height=500,
            width=800
        )
        st.plotly_chart(fig, use_container_width=True)
            
